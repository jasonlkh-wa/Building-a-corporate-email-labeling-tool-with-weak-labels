#%%
from enum import auto
import numpy as np
import pandas as pd
import os, re, functools
from IPython.display import display
from functools import reduce
from joblib import dump, load
import matplotlib.pyplot as plt
from scipy.sparse.base import spmatrix
import seaborn as sns
from snorkel.preprocess import preprocessor
from snorkel.labeling import labeling_function, PandasLFApplier, LFAnalysis
from snorkel.labeling.model import LabelModel
from EmailClassification_BasicFunction import import_pickle, regex_tokenizer, extract_bodymsg
from nltk.corpus import stopwords
stopwords = stopwords.words('english')
import warnings
warnings.filterwarnings('ignore')
np.random.seed(1)

SPAM = 1 
HAM = 0
ABSTAIN = -1

@labeling_function()
def survey(df):
    return SPAM if re.search("survey", df['msg']) else ABSTAIN

@labeling_function()
def newswire(df):
    return SPAM if re.search("newswire", df['msg']) and re.search('tr\'s', df['msg']) else ABSTAIN

@labeling_function()
def haas_promotion_address(df):
    return SPAM if "eveningmba@haas.berkeley.edu" in df['To'] else ABSTAIN

@labeling_function()
def career(df):
    return SPAM if re.search("career", df['msg']) else ABSTAIN

@labeling_function()
def venturewire(df):  # venture is an email address that send spam frequently
    return SPAM if re.search("venturewire", df['msg']) else ABSTAIN

@labeling_function()
def haas(df):  # haas is the name of the school program
    return SPAM if re.search("haas", df['msg']) else ABSTAIN

@labeling_function()
def mba(df):
    return SPAM if re.search("mba", df['msg']) else ABSTAIN

@labeling_function()
def berkeley(df):
    return SPAM if re.search('berkeley', df['msg']) else ABSTAIN

@labeling_function()
def student(df):
    return SPAM if re.search('student', df['msg']) and  re.search('mba', df['msg']) else ABSTAIN

@labeling_function()
def member(df):
    return SPAM if re.search("member", df['msg']) else ABSTAIN

@labeling_function()
def miss_opportunity(df):
    return SPAM if re.search("miss[\w\W]+(opportunity|opportunities)", df['msg']) else ABSTAIN

@labeling_function()
def subscribe(df):
    return SPAM if re.search("subscribe", df['msg']) else ABSTAIN

@labeling_function()
def unsubscribe(df):
    return SPAM if re.search("unsubscribe", df['msg']) else ABSTAIN

@labeling_function()
def subscription(df):
    return SPAM if re.search("subscription", df['msg']) else ABSTAIN

@labeling_function()
def click_link(df):
    return SPAM if re.search("(visit|click)[\w|\W]+(here|link|website)", df['msg']) else ABSTAIN

@labeling_function()
def discount(df):
    return SPAM if re.search("discount", df['msg']) else ABSTAIN

@labeling_function()
def advertisement(df):
    return SPAM if re.search("advertisement", df['msg']) else ABSTAIN

@labeling_function()
def read_more(df):
    return SPAM if re.search("read more|learn more|know more", df['msg']) else ABSTAIN

@labeling_function()
def register(df):
    return SPAM if re.search("register", df['msg']) else ABSTAIN

@labeling_function()
def automatic(df):
    return SPAM if re.search("automatic|autogenerated", df['msg']) else ABSTAIN

@labeling_function()
def store(df):
    return SPAM if re.search("store", df['msg']) else ABSTAIN

@labeling_function()
def alert(df):
    return SPAM if re.search("alert", df['msg']) else ABSTAIN

@labeling_function()
def notification(df):
    return SPAM if re.search("notification", df['msg']) else ABSTAIN

@labeling_function()
def draft(df):
    return HAM if re.search("draft", df['msg']) else ABSTAIN

@labeling_function()
def enron(df):
    return HAM if re.search("\senron\s", df['msg']) else ABSTAIN

@labeling_function()
def hotmail(df):
    return HAM if 'hotmail' in df['address_type'] else ABSTAIN

@labeling_function()
def search_for_I(df):
    return HAM if len(re.findall("\si\s|\si\'\w+", df['msg']))>1 else ABSTAIN

@labeling_function()
def count_to_enron(df):
    return HAM if df['count_to_enron'] > 1 else ABSTAIN

@labeling_function()
def reply(df):
    return HAM if re.search("re:", df['msg']) else ABSTAIN

@labeling_function()
def forward(df):
    return HAM if re.search("fw:|fwd:", df['msg']) else ABSTAIN

@labeling_function()
def jeff_count(df): #sjeff is the name of email owner
    return HAM if len(re.findall("jeff", df['msg']))>1 else ABSTAIN

@labeling_function()
def government(df):
    return HAM if re.search("government", df['msg']) else ABSTAIN

@labeling_function()
def confidential(df):
    return HAM if re.search("confidential", df['msg']) else ABSTAIN

@labeling_function()
def offset_cc_haas_berkeley(df):
    return HAM if re.search("@haas.berkeley|@haas|@berkely", df['msg']) else ABSTAIN

@labeling_function()
def let_me(df):
    return HAM if re.search('let me', df['msg']) else ABSTAIN

@labeling_function()
def fyi(df):
    return HAM if re.search('fyi|for your info|for your reference', df['msg']) else ABSTAIN


if __name__ == '__main__':
    if 'raw' not in globals():
        raw = import_pickle("..\data\emails_processed_cleaning_bySender_v2.pkl")
        raw['Date'] = pd.to_datetime(raw.loc[:, 'Date'])
    enron_address_list = ['mailman.enron.com', 'enron.com>', 'enron.net',\
    'nahou-lnww01.ots.enron.com', 'mailboy.enron.com',\
    'piassick".@enron@enron.com>', 'enron.com']  # enron email address patter
    snorkel_hand_label_set = pd.read_csv(r'..\data\dasovich_snorkel400_ground_label.csv', index_col=0)

    df = raw[raw['file']=='dasovich-j']
    df = df.sort_values(by='Date')
    pre_external = df[~df['address_type'].isin(enron_address_list)].sort_values(by='Date')

    # Export Internal email for later usage
    internal = df[df['address_type'].isin(enron_address_list)].sort_values(by='Date')
    dump(internal, r'..\data\dasovich_topic_model\dasovich_internal_emails')

    validation_set = pre_external.iloc[-600:, :]  # hold out part of data for validation (will be manually labeled)
    pre_external = pre_external.iloc[:-600, :]
    snorkel_test_set = pre_external.loc[snorkel_hand_label_set.index, :]
    pre_external = pre_external.loc[~pre_external.index.isin(snorkel_hand_label_set.index), :]
    preview_snorkel_test = snorkel_test_set.loc[:, ['body_msg', 'Subject', 'From', 'To']]

    pre_external = pre_external.loc[:, ['body_msg', 'Subject', 'address_type', 'To']]
    pre_external['msg'] = extract_bodymsg(pre_external).applymap(str.lower)
    pre_external['msg_token'] = pre_external['msg'].apply(regex_tokenizer, stopwords=stopwords, limit=False)
    pre_external['count_to_enron'] = pre_external['To'].apply(str.split, sep=',').apply(lambda x: len([i for i in x if 'enron' in i]))
    external = pre_external.loc[:, ['msg', 'msg_token', 'address_type', 'count_to_enron', 'To']]
    
    # snorkel
    lfs = [newswire, career, haas_promotion_address, venturewire, student, subscribe,
            unsubscribe, subscription, click_link, advertisement, read_more, register, 
            notification, draft, enron, count_to_enron, reply, jeff_count,
            fyi, let_me]  
    applier = PandasLFApplier(lfs=lfs) 
    L_train = applier.apply(df=external)

    # LabelModel
    label_model = LabelModel(cardinality=2, verbose=True)
    label_model.fit(L_train = L_train, n_epochs = 500, log_freq = 100, seed = 1)
    external['label'] = label_model.predict(L_train)
    print(LFAnalysis(L=L_train, lfs=lfs).lf_summary())
    print(external['label'].value_counts())
    preview = external[external['label']==1]

    # Test snorkel model with 400 ground label 
    test_external = snorkel_test_set.loc[:, ['body_msg', 'Subject', 'address_type', 'To']]
    test_external['msg'] = extract_bodymsg(test_external).applymap(str.lower)
    test_external['msg_token'] = test_external['msg'].apply(regex_tokenizer, stopwords=stopwords, limit=False)
    test_external['count_to_enron'] = test_external['To'].apply(str.split, sep=',').apply(lambda x: len([i for i in x if 'enron' in i]))
    test_external = test_external.loc[:, ['msg', 'msg_token', 'address_type', 'count_to_enron', 'To']]

    L_test = applier.apply(df=test_external)
    test_gold_label = pd.read_csv(r'..\data\dasovich_snorkel400_ground_label.csv')['label']
    display(LFAnalysis(L=L_test, lfs=lfs).lf_summary(test_gold_label.values))  # for showing summary
    test_external['label'] = label_model.predict(L_test)
    print('validation value count:', test_external['label'].value_counts())
    print(label_model.score(L=L_test, Y=test_gold_label, metrics=['accuracy', 'precision', 'recall', 'f1']))

    # Export model predicted data
    test_external['label'] = np.array(test_gold_label)
    final_output = pd.concat([external, test_external], axis=0)
    labeled_data = df.loc[final_output.index[final_output['label'] != -1]]
    unlabeled_data = df.loc[final_output.index[final_output['label'] == -1]]
    labeled_data = pd.concat([labeled_data, final_output.loc[:, ['msg_token', 'count_to_enron', 'label']]], join='inner', axis=1)
    dump([labeled_data, unlabeled_data, validation_set], r'..\data\dasovich_labeled_data_v3.joblib')
